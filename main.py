# -*- coding: utf-8 -*-
"""full code.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1vPRO2UWbN1Q5MK-kXqjvV_r8yVzrY4Av
"""

import keras
from keras.layers import Activation, Dense, Dropout, Conv2D, \
                         Flatten, MaxPooling2D, BatchNormalization
from keras.models import Sequential
import librosa
import librosa.display
import numpy as np
import pandas as pd
import random
import sklearn
import warnings
warnings.filterwarnings('ignore')

import os
from pydub import AudioSegment

from shennong.audio import Audio
from shennong.features.processor.rastaplp import RastaPlpProcessor


from shennong.audio import Audio
from shennong.features.processor.plp import PlpProcessor
from pathlib import Path

import matplotlib.pyplot as plt
plt.figure(figsize=(10, 4))
librosa.display.specshow(mfccs, x_axis='time')
plt.colorbar()
plt.title('MFCC')
plt.tight_layout()
plt.show()

# Read Data of test samples
data = pd.read_csv('F:\paper\Bangla ASR\segmented/metadata/test.csv')
data.head(5)

# Read Data of train samples
data = pd.read_csv('/home/raffael/bangla asr/metadata/source 3/train_messenger.csv')
train_data = data[['slice_file_name', 'fold' ,'classID']]
train_data['path'] = 'fold' + train_data['fold'].astype('str') + '/' + train_data['slice_file_name'].astype('str')

# Read Data of train samples
#data = pd.read_csv('/home/raffael/bangla asr/metadata/source 3/test.csv')
#test_data = data[['slice_file_name', 'fold' ,'classID']]
#test_data['path'] = 'fold' + test_data['fold'].astype('str') + '/' + test_data['slice_file_name'].astype('str')


# Read Data of train samples
data = pd.read_csv('/home/raffael/bangla asr/metadata/source 3/validation_messenger.csv')
valid_data = data[['slice_file_name', 'fold' ,'classID']]
valid_data['path'] = 'fold' + valid_data['fold'].astype('str') + '/' + valid_data['slice_file_name'].astype('str')

#make each file 3 sec
for row in train_data.itertuples():
    sound1 = AudioSegment.from_file('F:\paper\Bangla ASR\DATA\SILENCE\Silence.wav')
    sound2 = AudioSegment.from_file('F:/paper/Bangla ASR/segmented/new/augmented 2/' + row.path)
    combined = sound1.overlay(sound2)
    combined.export("F:/paper/Bangla ASR/combined.wav", format='wav')
    src='F:\paper\Bangla ASR\combined.wav'  
    dst ='F:\paper\Bangla ASR\segmented/augmented/2/fold'+ str(row.fold) + '/'   + row.slice_file_name
    os.rename(src, dst) 
    
#same goes for test & validation

#rasta plp feature extraction for files
MB1 = [] # Dataset
for row in test_data.itertuples():
    audio = Audio.load('/home/raffael/bangla asr/3s/data(204)/noisy/cafe/test/' + (row.path))
    processor = RastaPlpProcessor()
    processor.sample_rate = audio.sample_rate
    processor.order =12
    rasta_plp= processor.process(audio.channel(0))
    if rasta_plp.shape != (298, 13): continue
    MB1.append( (rasta_plp.data, row.classID) )
    
#same goes for test & validation

a

#save extracted files

import pickle

###Load into file
with open("M8.pkl","wb") as f:
    pickle.dump(M8,f)

#load saved extracted files
with open("/content/drive/My Drive/Colab Notebooks/FINAL_bfcc3.pkl","rb") as f:
    FINAL_bfcc3 = pickle.load(f)

tr = M7
te = M8
va=  M8

random.shuffle(tr)
random.shuffle(te)
random.shuffle(va)


X_train, y_train            = zip(*tr)
X_test, y_test              = zip(*te)
X_validation, y_validation  = zip(*va)


# Reshape for CNN input
X_train = np.array([x.reshape( (298,39,1) ) for x in X_train])
X_test = np.array([x.reshape( (298,39,1)) for x in X_test])
X_validation = np.array([x.reshape( (298,39,1) ) for x in X_validation])

# One-Hot encoding for classes
y_train = np.array(keras.utils.to_categorical(y_train, 11))
y_test = np.array(keras.utils.to_categorical(y_test, 11))
y_validation = np.array(keras.utils.to_categorical(y_validation, 11))


model = Sequential()
input_shape=(298,39,1)
model = Sequential()
model.add(Conv2D(32, (3, 3), padding='same',
                 input_shape=input_shape , kernel_regularizer=l2(0.001)))
model.add(Activation('relu'))
model.add(Conv2D(32, (3, 3)))
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Dropout(0.25))

model.add(Conv2D(64, (3, 3), padding='same'))
model.add(Activation('relu'))
model.add(Conv2D(64, (3, 3)))
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Dropout(0.25))

model.add(Flatten())
model.add(Dense(512))
model.add(Activation('relu'))
model.add(Dropout(0.5))
model.add(Dense(11))
model.add(Activation('softmax'))





model.compile(
	optimizer="Adam",
	loss="categorical_crossentropy",
	metrics=['accuracy'])

history=model.fit(
	x=X_train, 
	y=y_train,
    epochs=100,
    batch_size=100,
    validation_data= (X_validation, y_validation),
    #callbacks=[tensorboard])
    #callbacks=[plot_losses]

        )

score = model.evaluate(
	x=X_test,
	y=y_test)
print('Test loss:', score[0])
print('Test accuracy:', score[1])

predictions = model.predict(X_test)
y_pred=predictions
from sklearn.metrics import confusion_matrix
cm=confusion_matrix(
    y_test.argmax(axis=1), predictions.argmax(axis=1))
print(cm)

print(history.history.keys())

# Commented out IPython magic to ensure Python compatibility.
import matplotlib.pyplot as plt
# %matplotlib inline
plt.plot(history.history['acc'])
plt.plot(history.history['val_acc'])
plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.savefig('plot 1 acc.png', dpi=300, bbox_inches='tight')
plt.show()

# Commented out IPython magic to ensure Python compatibility.
# summarize history for loss
import matplotlib.pyplot as plt
# %matplotlib inline
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.savefig('plot 1 loss.png', dpi=300, bbox_inches='tight')
plt.show()

# save model and architecture to single file
model.save("1.h5")

# load model
model = keras.models.load_model('ModelMfcc52-whole augmentation 140 epoch-6 norm.h5')