# -*- coding: utf-8 -*-
"""Noise Injection.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1x1bNt20j1P3TrKmPxwYvJVGT_5KArqTd
"""

import keras
from keras.layers import Activation, Dense, Dropout, Conv2D, \
                         Flatten, MaxPooling2D, BatchNormalization
from keras.models import Sequential
import librosa
import librosa.display
import numpy as np
import pandas as pd
import random
import sklearn
import warnings
warnings.filterwarnings('ignore')

import os
from pydub import AudioSegment

from shennong.audio import Audio
from shennong.features.processor.rastaplp import RastaPlpProcessor


from shennong.audio import Audio
from shennong.features.processor.plp import PlpProcessor
from pathlib import Path



from pydub import AudioSegment
from pydub.playback import play

# Read Data of train samples
data = pd.read_csv('/home/raffael/bangla asr/3s/data(204)/metadata/train.csv')
train_data = data[['slice_file_name', 'fold' ,'classID']]
train_data['path'] = 'fold' + train_data['fold'].astype('str') + '/' + train_data['slice_file_name'].astype('str')

# Read Data of train samples
data = pd.read_csv('/home/raffael/bangla asr/3s/data(204)/metadata/test.csv')
test_data = data[['slice_file_name', 'fold' ,'classID']]
test_data['path'] = 'fold' + test_data['fold'].astype('str') + '/' + test_data['slice_file_name'].astype('str')

# Read Data of train samples
data = pd.read_csv('/home/raffael/bangla asr/3s/data(204)/metadata/validation.csv')
validation_data = data[['slice_file_name', 'fold' ,'classID']]
validation_data['path'] = 'fold' + validation_data['fold'].astype('str') + '/' + validation_data['slice_file_name'].astype('str')

len(MFCC2)

from pydub import AudioSegment
from pydub.playback import play
loop = AudioSegment.from_wav("streets.wav") #load the audio file
#loop2 = loop*2 # make the audio clip's duration twice
loop = loop - 2
#play(loop)
loop.export("streets 2.wav", format="wav")  # save the edited audio file

import soundfile as sf

data, samplerate = sf.read('streets 2.wav')
a=data
b=20*np.log10(np.sqrt(np.mean(np.absolute(a)**2))) # db calculate
print(b)

loop = AudioSegment.from_wav("streets 2.wav")
play(loop)

from pydub import AudioSegment

sound1 = AudioSegment.from_file("/home/raffael/bangla asr/Silence.wav")
sound2 = AudioSegment.from_file("/home/raffael/bangla asr/rail 2.wav")

combined = sound1.overlay(sound2)

combined.export("/home/raffael/bangla asr/combined.wav", format='wav')

for row in test_data.itertuples():
    sound1 = AudioSegment.from_file('/home/raffael/bangla asr/rail.wav')
    sound2 = AudioSegment.from_file('/home/raffael/bangla asr/3s/data(204)/test/' + row.path)
    combined = sound1.overlay(sound2)
    combined.export( '/home/raffael/bangla asr/3s/data(204)/noisy/test/fold' + str(row.fold) + '/combined.wav' , format='wav')
    src='/home/raffael/bangla asr/3s/data(204)/noisy/test/fold' + str(row.fold) + '/combined.wav'
    dst ='/home/raffael/bangla asr/3s/data(204)/noisy/test/fold' + str(row.fold) + '/'   + row.slice_file_name
    os.rename(src, dst)

PN4=[]
for row in test_data.itertuples():
    y , sr =librosa.load('/home/raffael/bangla asr/3s/data(204)/noisy/rail/test/' + row.path)
    a=pncc(y)
    if a.shape != (411,13):continue
    PN4.append((a,row.classID))

MB5 = [] # Dataset
for row in test_data.itertuples():
    audio = Audio.load('/home/raffael/bangla asr/3s/data(204)/noisy/street/test/' + (row.path))
    processor = RastaPlpProcessor()
    processor.sample_rate = audio.sample_rate
    processor.order =12
    rasta_plp= processor.process(audio.channel(0))
    if rasta_plp.shape != (298, 13): continue
    MB5.append( (rasta_plp.data, row.classID) )

D1=[]
#MFCC feature extraction for augmented files
for row in train_data.itertuples():
    y, sr = librosa.load('/home/raffael/bangla asr/3s/data(204)/noisy/ac/train/' + (row.path))  
    ps = librosa.feature.mfcc(y=y, sr=sr , n_mfcc=39)
    if ps.shape != (39, 130): continue
    D1.append( (ps, row.classID) )