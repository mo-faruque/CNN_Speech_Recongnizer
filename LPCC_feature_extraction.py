# -*- coding: utf-8 -*-
"""final LPCC.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1NL-kU8Lh7dur1VLf34ISmtRSCzE1D_pU
"""

import keras
from keras.layers import Activation, Dense, Dropout, Conv2D, \
                         Flatten, MaxPooling2D, BatchNormalization
from keras.models import Sequential
import librosa
import librosa.display
import numpy as np
import pandas as pd
import random
import sklearn
import warnings
warnings.filterwarnings('ignore')

import os
from pydub import AudioSegment

from shennong.audio import Audio
from shennong.features.processor.rastaplp import RastaPlpProcessor


from shennong.audio import Audio
from shennong.features.processor.plp import PlpProcessor
from pathlib import Path

import pickle


from pydub import AudioSegment
from pydub.playback import play

# Read Data of train samples
data = pd.read_csv('/home/raffael/bangla asr/3s/metadata/all xxx train.csv')
train_data= data[['slice_file_name', 'fold' ,'classID']]
train_data['path'] = 'fold' + train_data['fold'].astype('str') + '/' + train_data['slice_file_name'].astype('str')

# Read Data of train samples
data = pd.read_csv('/home/raffael/bangla asr/3s/metadata/all xxx test.csv')
test_data = data[['slice_file_name', 'fold' ,'classID']]
test_data['path'] = 'fold' + test_data['fold'].astype('str') + '/' + test_data['slice_file_name'].astype('str')


# Read Data of train samples
data = pd.read_csv('/home/raffael/bangla asr/3s/metadata/all xxx validation.csv')
validation_data = data[['slice_file_name', 'fold' ,'classID']]
validation_data['path'] = 'fold' + validation_data['fold'].astype('str') + '/' + validation_data['slice_file_name'].astype('str')

import scipy
from spafe.utils import vis
from spafe.features.lpc import lpcc

# init input vars
num_ceps = 13
lifter = 0
normalize = False

##Extract from file
with open("lp-nps-4.pkl","rb") as f:
    lpf = pickle.load(f)
#here 'a' array is saved & 'a' array is loaded into 'b' array

import librosa
librosa.get_duration(filename='/home/raffael/bangla asr/3s/all/augment/nps/-2/fold1/GMJ Priyo_s friend_00.wav')

home/raffael/bangla asr/3s/all/augment/nps/-2/fold1/GMJ Priyo_s friend_00.wav'

len(lpf)

LPC1=[]
for row in train_data.itertuples():    
    fs, sig = scipy.io.wavfile.read('/home/raffael/bangla asr/3s/all/augment/pps/2/fold'+ str(row.fold) + '/'   + row.slice_file_name)

    lpccs = lpcc(sig=sig, fs=fs, num_ceps=num_ceps, lifter=lifter, normalize=normalize)
    a=lpccs
    if a.shape != (306,13):continue
    LPC1.append((a,row.classID))

for row in train_data.itertuples():
    y, sr = librosa.load('/home/raffael/bangla asr/3s/all/train/' + row.path)  
    y_changed = librosa.effects.time_stretch(y, rate= 1.5)
    librosa.output.write_wav('/home/raffael/bangla asr/3s/a/pts/1.5/fold'+ str(row.fold) + '/'   + row.slice_file_name , y_changed, sr)
    

for row in train_data.itertuples():
    sound1 = AudioSegment.from_file('/home/raffael/bangla asr/Silence.wav')
    sound2 = AudioSegment.from_file('/home/raffael/bangla asr/3s/a/pts/1.5/' + row.path)
    combined = sound1.overlay(sound2)
    combined = sound1.overlay(sound2)
    combined.export( '/home/raffael/bangla asr/3s/all/augment/pts/1.5/fold' + str(row.fold) + '/combined.wav' , format='wav')
    src='/home/raffael/bangla asr/3s/all/augment/pts/1.5/fold' + str(row.fold) + '/combined.wav'
    dst ='/home/raffael/bangla asr/3s/all/augment/pts/1.5/fold' + str(row.fold) + '/'   + row.slice_file_name
    os.rename(src, dst)
    
LPC1=[]
for row in train_data.itertuples():    
    fs, sig = scipy.io.wavfile.read('/home/raffael/bangla asr/3s/all/augment/pts/1.5/' + row.path)

    lpccs = lpcc(sig=sig, fs=fs, num_ceps=num_ceps, lifter=lifter, normalize=normalize)
    a=lpccs
    if a.shape != (306,13):continue
    LPC1.append((a,row.classID))
    
import pickle

###Load into file
with open("lp-pts-1.5.pkl","wb") as f:
    pickle.dump(LPC1,f)

D=[]
for row in train_data.itertuples():
    y, sr = librosa.load('/home/raffael/bangla asr/3s/all/augment/pps/2/' + (row.path))  
    ps = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=39)
    if ps.shape != (39, 130): continue
    D.append( (ps, row.classID) )
    
###Load into file
with open("mf-pps-2.pkl","wb") as f:
    pickle.dump(D,f)